## 5.1 Java 内存模型

JMM 即 Java Memory Model，它定义了主存、工作内存抽象概念，底层对应着 CPU 寄存器、缓存、硬件内存、CPU 指令优化等。

JMM 体现在以下几个方面

>原子性 - 保证指令不会受到线程上下文切换的影响

>可见性 - 保证指令不会受 cpu 缓存的影响

>有序性 - 保证指令不会受 cpu 指令并行优化的影响


## 5.2 可见性

### 退不出的循环

先来看一个现象，main 线程对 run 变量的修改对于 t 线程不可见，导致了 t 线程无法停止：
```java
static boolean run = true;
public static void main(String[] args) throws InterruptedException {
    Thread t = new Thread(() - > {
        while(run) {
            // ....
        }
    });
    t.start();
    sleep(1);
    run = false; // 线程t不会如预想的停下来
}
```
为什么呢？分析一下：

1. 初始状态， t 线程刚开始从主内存读取了 run 的值到工作内存。

![](img/5.1.png)

2. 因为 t 线程要频繁从主内存中读取 run 的值，JIT 编译器会将 run 的值缓存至自己工作内存中的高速缓存中，减少对主存中 run 的访问，提高效率

![](img/5.2.png)

3. 1 秒之后，main 线程修改了 run 的值，并同步至主存，而 t 是从自己工作内存中的高速缓存中读取这个变量的值，结果永远是旧值

![](img/5.3.png)

### 解决方法

volatile（易变关键字）

它可以用来修饰成员变量和静态成员变量，他可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存

### 可见性 vs 原子性

前面例子体现的实际就是可见性，它保证的是在多个线程之间，一个线程对 volatile 变量的修改对另一个线程可见， 不能保证原子性，仅用在一个写线程，多个读线程的情况： 上例从字节码理解是这样的：
```java
getstatic run // 线程 t 获取 run true
getstatic run // 线程 t 获取 run true
getstatic run // 线程 t 获取 run true
getstatic run // 线程 t 获取 run true
putstatic run // 线程 main 修改 run 为 false， 仅此一次
getstatic run // 线程 t 获取 run false 
```
比较一下之前我们将线程安全时举的例子：两个线程一个 i++ 一个 i-- ，只能保证看到最新值，不能解决指令交错

```java
// 假设i的初始值为0
getstatic i // 线程2-获取静态变量i的值 线程内i=0
getstatic i // 线程1-获取静态变量i的值 线程内i=0
iconst_1 // 线程1-准备常量1
iadd // 线程1-自增 线程内i=1
putstatic i // 线程1-将修改后的值存入静态变量i 静态变量i=1
iconst_1 // 线程2-准备常量1
isub // 线程2-自减 线程内i=-1
putstatic i // 线程2-将修改后的值存入静态变量i 静态变量i=-1
```

>注意 synchronized 语句块既可以保证代码块的原子性，也同时保证代码块内变量的可见性。但缺点是synchronized 是属于重量级操作，性能相对更低
>
>如果在前面示例的死循环中加入 System.out.println() 会发现即使不加 volatile 修饰符，线程 t 也能正确看到对 run 变量的修改了，想一想为什么？

### * 原理之 CPU 缓存结构

#### 1. CPU 缓存结构

![](img/5.4.png)

查看 cpu 缓存
```java
⚡ root@yihang01 ~ lscpu
Architecture: x86_64
CPU op-mode(s): 32-bit, 64-bit
Byte Order: Little Endian
CPU(s): 1
On-line CPU(s) list: 0
Thread(s) per core: 1
Core(s) per socket: 1
Socket(s): 1
NUMA node(s): 1
Vendor ID: GenuineIntel
CPU family: 6
Model: 142
Model name: Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz
Stepping: 11
CPU MHz: 1992.002
BogoMIPS: 3984.00
Hypervisor vendor: VMware
Virtualization type: full
L1d cache: 32K
L1i cache: 32K
L2 cache: 256K
L3 cache: 8192K
NUMA node0 CPU(s): 0
```
速度比较

![](img/5.5.png)

查看 cpu 缓存行
```java
⚡ root@yihang01 ~ cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size
64
```
cpu 拿到的内存地址格式是这样的
```java
[高位组标记][低位索引][偏移量]
```

![](img/5.6.png)

#### 2. CPU 缓存读

读取数据流程如下

>根据低位，计算在缓存中的索引
>
>判断是否有效
>>
>>0 去内存读取新数据更新缓存行
>>
>>1 再对比高位组标记是否一致
>>>
>>>一致，根据偏移量返回缓存数据
>>>不一致，去内存读取新数据更新缓存行

#### 3. CPU 缓存一致性

MESI 协议

1. E、S、M 状态的缓存行都可以满足 CPU 的读请求

2. E 状态的缓存行，有写请求，会将状态改为 M，这时并不触发向主存的写

3. E 状态的缓存行，必须监听该缓存行的读操作，如果有，要变为 S 状态

![](img/5.7.png)

4. M 状态的缓存行，必须监听该缓存行的读操作，如果有，先将其它缓存（S 状态）中该缓存行变成 I 状态（即6. 的流程），写入主存，自己变为 S 状态

5. S 状态的缓存行，有写请求，走 4. 的流程

6. S 状态的缓存行，必须监听该缓存行的失效操作，如果有，自己变为 I 状态

7. I 状态的缓存行，有读请求，必须从主存读取

![](img/5.8.png)

#### 4. 内存屏障

Memory Barrier（Memory Fence）

>可见性
>>
>>写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中
>>
>>而读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据
>
>有序性
>
>>写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后
>>
>>读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前

![](img/5.9.png)

### * 模式之两阶段终止

Two Phase Termination

在一个线程 T1 中如何“优雅”终止线程 T2？这里的【优雅】指的是给 T2 一个料理后事的机会。

#### 1. 错误思路

>使用线程对象的 stop() 方法停止线程
>
>>stop 方法会真正杀死线程，如果这时线程锁住了共享资源，那么当它被杀死后就再也没有机会释放锁，其它线程将永远无法获取锁
>
>使用 System.exit(int) 方法停止线程
>>
>>目的仅是停止一个线程，但这种做法会让整个程序都停止

#### 2. 两阶段终止模式

![](img/5.10.png)

##### 2.1 利用 isInterrupted

`interrupt` 可以打断正在执行的线程，无论这个线程是在 `sleep`，`wait`，还是正常运行
```java
class TPTInterrupt {
    private Thread thread;
    public void start() {
        thread = new Thread(() - > {
            while(true) {
                Thread current = Thread.currentThread();
                if(current.isInterrupted()) {
                    log.debug("料理后事");
                    break;
                }
                try {
                    Thread.sleep(1000);
                    log.debug("将结果保存");
                } catch(InterruptedException e) {
                    current.interrupt();
                }
                // 执行监控操作
            }
        }, "监控线程");
        thread.start();
    }
    public void stop() {
        thread.interrupt();
    }
}
```
调用
```java
TPTInterrupt t = new TPTInterrupt();
t.start();
Thread.sleep(3500);
log.debug("stop");
t.stop();
```
结果
```java
11:49:42.915 c.TwoPhaseTermination [监控线程] - 将结果保存
11:49:43.919 c.TwoPhaseTermination [监控线程] - 将结果保存
11:49:44.919 c.TwoPhaseTermination [监控线程] - 将结果保存
11:49:45.413 c.TestTwoPhaseTermination [main] - stop
11:49:45.413 c.TwoPhaseTermination [监控线程] - 料理后事
```

##### 2.2 利用停止标记
```java
// 停止标记用 volatile 是为了保证该变量在多个线程之间的可见性
// 我们的例子中，即主线程把它修改为 true 对 t1 线程可见
class TPTVolatile {
    private Thread thread;
    private volatile boolean stop = false;
    public void start() {
        thread = new Thread(() - > {
            while(true) {
                Thread current = Thread.currentThread();
                if(stop) {
                    log.debug("料理后事");
                    break;
                }
                try {
                    Thread.sleep(1000);
                    log.debug("将结果保存");
                } catch(InterruptedException e) {}
                // 执行监控操作
            }
        }, "监控线程");
        thread.start();
    }
    public void stop() {
        stop = true;
        thread.interrupt();
    }
}
```
调用
```java
TPTVolatile t = new TPTVolatile();
t.start();
Thread.sleep(3500);
log.debug("stop");
t.stop();
```
结果
```java
11:54:52.003 c.TPTVolatile [监控线程] - 将结果保存
11:54:53.006 c.TPTVolatile [监控线程] - 将结果保存
11:54:54.007 c.TPTVolatile [监控线程] - 将结果保存
11:54:54.502 c.TestTwoPhaseTermination [main] - stop
11:54:54.502 c.TPTVolatile [监控线程] - 料理后事
```

#### * 同步模式之 Balking

##### 1. 定义

Balking （犹豫）模式用在一个线程发现另一个线程或本线程已经做了某一件相同的事，那么本线程就无需再做了，直接结束返回

##### 2. 实现
例如：
```java
public class MonitorService {
    // 用来表示是否已经有线程已经在执行启动了
    private volatile boolean starting;
    public void start() {
        log.info("尝试启动监控线程...");
        synchronized(this) {
                if(starting) {
                    return;
                }
                starting = true;
            }
            // 真正启动监控线程...
    }
}
```
当前端页面多次点击按钮调用 start 时

输出
```java
[http-nio-8080-exec-1] cn.itcast.monitor.service.MonitorService - 该监控线程已启动?(false)
[http-nio-8080-exec-1] cn.itcast.monitor.service.MonitorService - 监控线程已启动...
[http-nio-8080-exec-2] cn.itcast.monitor.service.MonitorService - 该监控线程已启动?(true)
[http-nio-8080-exec-3] cn.itcast.monitor.service.MonitorService - 该监控线程已启动?(true)
[http-nio-8080-exec-4] cn.itcast.monitor.service.MonitorService - 该监控线程已启动?(true)
```
它还经常用来实现线程安全的单例
```java
public final class Singleton {
    private Singleton() {}
    private static Singleton INSTANCE = null;
    public static synchronized Singleton getInstance() {
        if(INSTANCE != null) {
            return INSTANCE;
        }
        INSTANCE = new Singleton();
        return INSTANCE;
    }
}
```

对比一下保护性暂停模式：保护性暂停模式用在一个线程等待另一个线程的执行结果，当条件不满足时线程等待。

## 5.3 有序性

JVM 会在不影响正确性的前提下，可以调整语句的执行顺序，思考下面一段代码

```java
static int i;
static int j;
// 在某个线程内执行如下赋值操作
i = ...;
j = ...; 
```

可以看到，至于是先执行 i 还是 先执行 j ，对最终的结果不会产生影响。所以，上面代码真正执行时，既可以是
```java
i = ...;
j = ...;
```
也可以是
```java
j = ...;
i = ...;
```
这种特性称之为『指令重排』，多线程下『指令重排』会影响正确性。为什么要有重排指令这项优化呢？从 CPU执行指令的原理来理解一下吧

### * 原理之指令级并行

#### 1. 名词

**Clock Cycle Time**

主频的概念大家接触的比较多，而 CPU 的 `Clock Cycle Time（时钟周期时间）`，等于主频的倒数，意思是 CPU 能够识别的最小时间单位，比如说 4G 主频的 CPU 的 Clock Cycle Time 就是 0.25 ns，作为对比，我们墙上挂钟的Cycle Time 是 1s

例如，运行一条加法指令一般需要一个时钟周期时间

**CPI**

有的指令需要更多的时钟周期时间，所以引出了 CPI （Cycles Per Instruction）`指令平均时钟周期数`

**IPC**

IPC（Instruction Per Clock Cycle） 即 CPI 的倒数，表示`每个时钟周期能够运行的指令数`

**CPU 执行时间**

程序的 CPU 执行时间，即我们前面提到的 user + system 时间，可以用下面的公式来表示
```java
程序 CPU 执行时间 = 指令数 * CPI * Clock Cycle Time
```

#### 2. 鱼罐头的故事

加工一条鱼需要 50 分钟，只能一条鱼、一条鱼顺序加工...

![](img/5.11.png)

可以将每个鱼罐头的加工流程细分为 5 个步骤：
>
>去鳞清洗 10分钟
>
>蒸煮沥水 10分钟
>
>加注汤料 10分钟
>
>杀菌出锅 10分钟
>
>真空封罐 10分钟

![](img/5.12.png)

即使只有一个工人，最理想的情况是：他能够在 10 分钟内同时做好这 5 件事，因为对第一条鱼的真空装罐，不会影响对第二条鱼的杀菌出锅...

#### 3. 指令重排序优化

事实上，现代处理器会设计为一个时钟周期完成一条执行时间最长的 CPU 指令。为什么这么做呢？可以想到指令还可以再划分成一个个更小的阶段，例如，每条指令都可以分为5 个阶段： 

`取指令 - 指令译码 - 执行指令 - 内存访问 - 数据写回`

![](img/5.13.png)

>**术语参考：**
>
>instruction fetch (IF)
>
>instruction decode (ID)
>
>execute (EX)
>
>memory access (MEM)
>
>register write back (WB)

在不改变程序结果的前提下，这些指令的各个阶段可以通过`重排序`和`组合`来实现`指令级并行`，这一技术在 80's 中叶到 90's 中叶占据了计算架构的重要地位。

>**提示：**
>
>分阶段，分工是提升效率的关键！

指令重排的前提是，重排指令不能影响结果，例如
```java
// 可以重排的例子
int a = 10; // 指令1
int b = 20; // 指令2
System.out.println( a + b );
// 不能重排的例子
int a = 10; // 指令1
int b = a - 5; // 指令2
```

>**参考：** Scoreboarding and the Tomasulo algorithm (which is similar to scoreboarding but makes use ofregister renaming) are two of the most common techniques for implementing out-of-order execution and instruction-level parallelism.

#### 4. 支持流水线的处理器

现代 CPU 支持`多级指令流水线`，例如支持同时执行 `取指令 - 指令译码 - 执行指令 - 内存访问 - 数据写回` 的处理器，就可以称之为`五级指令流水线`。这时 CPU 可以在一个时钟周期内，同时运行五条指令的不同阶段（相当于一条执行时间最长的复杂指令），IPC = 1，本质上，流水线技术并不能缩短单条指令的执行时间，但它变相地提高了指令地吞吐率。

![](img/5.14.png)

#### 5. SuperScalar 处理器

大多数处理器包含多个执行单元，并不是所有计算功能都集中在一起，可以再细分为整数运算单元、浮点数运算单元等，这样可以把多条指令也可以做到并行获取、译码等，CPU 可以在一个时钟周期内，执行多于一条指令，IPC> 1

![](img/5.15.png)

![](img/5.16.png)

**诡异的结果**

```java
int num = 0;
boolean ready = false;
// 线程1 执行此方法
public void actor1(I_Result r) {
        if(ready) {
            r.r1 = num + num;
        } else {
            r.r1 = 1;
        }
    }
    // 线程2 执行此方法
public void actor2(I_Result r) {
    num = 2;
    ready = true;
}
```
I_Result 是一个对象，有一个属性 r1 用来保存结果，问，可能的结果有几种？

有同学这么分析

情况1：线程1 先执行，这时 ready = false，所以进入 else 分支结果为 1

情况2：线程2 先执行 num = 2，但没来得及执行 ready = true，线程1 执行，还是进入 else 分支，结果为1

情况3：线程2 执行到 ready = true，线程1 执行，这回进入 if 分支，结果为 4（因为 num 已经执行过了）

但结果还有可能是 0 

这种情况下是：线程2 执行 ready = true，切换到线程1，进入 if 分支，相加为 0，再切回线程2 执行 num = 2

这种现象叫做指令重排，是 JIT 编译器在运行时的一些优化，这个现象需要通过大量测试才能复现：

借助 java 并发压测工具 jcstress https://wiki.openjdk.java.net/display/CodeTools/jcstress

```java
mvn archetype:generate -DinteractiveMode=false -DarchetypeGroupId=org.openjdk.jcstress -
DarchetypeArtifactId=jcstress-java-test-archetype -DarchetypeVersion=0.5 -DgroupId=cn.itcast -
DartifactId=ordering -Dversion=1.0 
```
创建 maven 项目，提供如下测试类
```java
@JCStressTest
@Outcome(id = {"1", "4"}, expect = Expect.ACCEPTABLE, desc = "ok")
@Outcome(id = "0", expect = Expect.ACCEPTABLE_INTERESTING, desc = "!!!!")
@State
public class ConcurrencyTest {
    int num = 0;
    boolean ready = false;
    
    @Actor
    public void actor1(I_Result r) {
        if(ready) {
            r.r1 = num + num;
        } else {
            r.r1 = 1;
        }
    }
    @Actor
    public void actor2(I_Result r) {
        num = 2;
        ready = true;
    }
}
```
执行
```java
mvn clean install
java -jar target/jcstress.jar
```
会输出我们感兴趣的结果，摘录其中一次结果：

```java
*** INTERESTING tests
 Some interesting behaviors observed. This is for the plain curiosity.
 2 matching test results.
 [OK] test.ConcurrencyTest
 (JVM args: [-XX:-TieredCompilation])
 Observed state Occurrences Expectation Interpretation
 0 1,729 ACCEPTABLE_INTERESTING !!!!
 1 42,617,915 ACCEPTABLE ok
 4 5,146,627 ACCEPTABLE ok
 [OK] test.ConcurrencyTest
 (JVM args: [])
 Observed state Occurrences Expectation Interpretation
 0 1,652 ACCEPTABLE_INTERESTING !!!!
 1 46,460,657 ACCEPTABLE ok
 4 4,571,072 ACCEPTABLE ok 

```
可以看到，出现结果为 0 的情况有 638 次，虽然次数相对很少，但毕竟是出现了

**解决方法**

volatile 修饰的变量，可以禁用指令重排
```java
@JCStressTest
@Outcome(id = {"1", "4"}, expect = Expect.ACCEPTABLE, desc = "ok")
@Outcome(id = "0", expect = Expect.ACCEPTABLE_INTERESTING, desc = "!!!!")
@State
public class ConcurrencyTest {
    int num = 0;
    volatile boolean ready = false;
    @Actor
    public void actor1(I_Result r) {
        if(ready) {
            r.r1 = num + num;
        } else {
            r.r1 = 1;
        }
    }
    @Actor
    public void actor2(I_Result r) {
        num = 2;
        ready = true;
    }
}
```
结果为：
```java
*** INTERESTING tests
 Some interesting behaviors observed. This is for the plain curiosity.
 0 matching test results.
```

### * 原理之 volatile

volatile 的底层实现原理是内存屏障，`Memory Barrier（Memory Fence）`

对 volatile 变量的写指令后会加入写屏障

对 volatile 变量的读指令前会加入读屏障

#### 1. 如何保证可见性

写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中
```java
public void actor2(I_Result r) {
    num = 2;
    ready = true; // ready 是 volatile 赋值带写屏障
    // 写屏障
}
```
而读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中最新数据
```java
public void actor1(I_Result r) {
    // 读屏障
    // ready 是 volatile 读取值带读屏障
    if(ready) {
        r.r1 = num + num;
    } else {
        r.r1 = 1;
    }
}
```

![](img/5.17.png)

#### 2. 如何保证有序性

写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后
```java
public void actor2(I_Result r) {
    num = 2;
    ready = true; // ready 是 volatile 赋值带写屏障
    // 写屏障
}
```
读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前
```java
public void actor1(I_Result r) {
    // 读屏障
    // ready 是 volatile 读取值带读屏障
    if(ready) {
        r.r1 = num + num;
    } else {
        r.r1 = 1;
    }
}
```

![](img/5.18.png)

还是那句话，不能解决指令交错：

写屏障仅仅是保证之后的读能够读到最新的结果，但不能保证读跑到它前面去

而有序性的保证也只是保证了本线程内相关代码不被重排序

![](img/5.19.png)

#### 3. double-checked locking 问题

以著名的 double-checked locking 单例模式为例
```java
public final class Singleton {
    private Singleton() {}
    private static Singleton INSTANCE = null;
    public static Singleton getInstance() {
        if(INSTANCE == null) { // t2
            // 首次访问会同步，而之后的使用没有 synchronized
            synchronized(Singleton.class) {
                if(INSTANCE == null) { // t1
                    INSTANCE = new Singleton();
                }
            }
        }
        return INSTANCE;
    }
}
```

以上的实现特点是：

>懒惰实例化
>
>首次使用 getInstance() 才使用 synchronized 加锁，后续使用时无需加锁
>
>有隐含的，但很关键的一点：第一个 if 使用了 INSTANCE 变量，是在同步块之外
>

但在多线程环境下，上面的代码是有问题的，getInstance 方法对应的字节码为：
```java
0: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;
3: ifnonnull 37
6: ldc #3 // class cn/itcast/n5/Singleton
8: dup
9: astore_0
10: monitorenter
11: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;
14: ifnonnull 27
17: new #3 // class cn/itcast/n5/Singleton
20: dup
21: invokespecial #4 // Method "<init>":()V
24: putstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;
27: aload_0
28: monitorexit
29: goto 37
32: astore_1
33: aload_0
34: monitorexit
35: aload_1
36: athrow
37: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;
40: areturn

```
其中

>17 表示创建对象，将对象引用入栈 // new Singleton
>
>20 表示复制一份对象引用 // 引用地址
>
>21 表示利用一个对象引用，调用构造方法
>
>24 表示利用一个对象引用，赋值给 static INSTANCE

也许 jvm 会优化为：先执行 24，再执行 21。如果两个线程 t1，t2 按如下时间序列执行：

![](img/5.20.png)

关键在于 0: getstatic 这行代码在 monitor 控制之外，它就像之前举例中不守规则的人，可以越过 monitor 读取INSTANCE 变量的值

这时 t1 还未完全将构造方法执行完毕，如果在构造方法中要执行很多初始化操作，那么 t2 拿到的是将是一个未初始化完毕的单例

对 INSTANCE 使用 volatile 修饰即可，可以禁用指令重排，但要注意在 JDK 5 以上的版本的 volatile 才会真正有效

#### 4. double-checked locking 解决
```java
public final class Singleton {
    private Singleton() {}
    private static volatile Singleton INSTANCE = null;
    public static Singleton getInstance() {
        // 实例没创建，才会进入内部的 synchronized代码块
        if(INSTANCE == null) {
            synchronized(Singleton.class) { // t2
                // 也许有其它线程已经创建实例，所以再判断一次
                if(INSTANCE == null) { // t1
                    INSTANCE = new Singleton();
                }
            }
        }
        return INSTANCE;
    }
}
```
字节码上看不出来 volatile 指令的效果
```java
// -------------------------------------> 加入对 INSTANCE 变量的读屏障
0: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;
3: ifnonnull 37
6: ldc #3 // class cn/itcast/n5/Singleton
8: dup
9: astore_0
10: monitorenter -----------------------> 保证原子性、可见性
11: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;
14: ifnonnull 27
17: new #3 // class cn/itcast/n5/Singleton
20: dup
21: invokespecial #4 // Method "<init>":()V
24: putstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;
// -------------------------------------> 加入对 INSTANCE 变量的写屏障
27: aload_0
28: monitorexit ------------------------> 保证原子性、可见性
29: goto 37
32: astore_1
33: aload_0
34: monitorexit
35: aload_1
36: athrow
37: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;
40: areturn
```
如上面的注释内容所示，读写 volatile 变量时会加入内存屏障（Memory Barrier（Memory Fence）），保证下面两点：

>可见性
>>
>>写屏障（sfence）保证在该屏障之前的 t1 对共享变量的改动，都同步到主存当中
>>
>>而读屏障（lfence）保证在该屏障之后 t2 对共享变量的读取，加载的是主存中最新数据
>
>有序性
>>
>>写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后
>>
>>读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前
>
>更底层是读写变量时使用 lock 指令来多核 CPU 之间的可见性与有序性

![](img/5.21.png)

**happens-before**

happens-before 规定了对共享变量的写操作对其它线程的读操作可见，它是可见性与有序性的一套规则总结，抛开以下 happens-before 规则，JMM 并不能保证一个线程对共享变量的写，对于其它线程对该共享变量的读可见

线程解锁 m 之前对变量的写，对于接下来对 m 加锁的其它线程对该变量的读可见
```java
static int x;
static Object m = new Object();
new Thread(() - > {
    synchronized(m) {
        x = 10;
    }
}, "t1").start();
new Thread(() - > {
    synchronized(m) {
        System.out.println(x);
    }
}, "t2").start();
```
线程对 volatile 变量的写，对接下来其它线程对该变量的读可见
```java
volatile static int x;
new Thread(() - > {
    x = 10;
}, "t1").start();
new Thread(() - > {
    System.out.println(x);
}, "t2").start();
```
线程 start 前对变量的写，对该线程开始后对该变量的读可见
```java
static int x;
x = 10;
new Thread(() - > {
    System.out.println(x);
}, "t2").start();
```
线程结束前对变量的写，对其它线程得知它结束后的读可见（比如其它线程调用 t1.isAlive() 或 t1.join()等待它结束）
```java
static int x;
Thread t1 = new Thread(() - > {
    x = 10;
}, "t1");
t1.start();
t1.join();
System.out.println(x);
```
线程 t1 打断 t2（interrupt）前对变量的写，对于其他线程得知 t2 被打断后对变量的读可见（通过t2.interrupted 或 t2.isInterrupted）
```java
static int x;
public static void main(String[] args) {
    Thread t2 = new Thread(() - > {
        while(true) {
            if(Thread.currentThread().isInterrupted()) {
                System.out.println(x);
                break;
            }
        }
    }, "t2");
    t2.start();
    new Thread(() - > {
        sleep(1);
        x = 10;
        t2.interrupt();
    }, "t1").start();
    while(!t2.isInterrupted()) {
        Thread.yield();
    }
    System.out.println(x);
}
```
对变量默认值（0，false，null）的写，对其它线程对该变量的读可见

具有传递性，如果 x hb-> y 并且 y hb-> z 那么有 x hb-> z ，配合 volatile 的防指令重排，有下面的例子

```java
volatile static int x;
static int y;
new Thread(() - > {
    y = 10;
    x = 20;
}, "t1").start();
new Thread(() - > {
    // x=20 对 t2 可见, 同时 y=10 也对 t2 可见
    System.out.println(x);
}, "t2").start();
```

>变量都是指成员变量或静态成员变量